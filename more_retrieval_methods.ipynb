{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49011f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "# Open the .mat file in read mode\n",
    "mat_file = h5py.File('queryDataset.mat', 'r')\n",
    "mat_file2 = h5py.File('wholeDataset.mat', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "542cfe79",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = mat_file['queryDataset']['pos']\n",
    "D = mat_file2['wholeDataset']['pos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d49d628",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "Qnp = np.array(Q)\n",
    "Dnp = np.array(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d7c8c39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2463, 93)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Qnp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59d92508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(378694, 93)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dnp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "babe70c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2463, 93)\n",
      "(378694, 93)\n"
     ]
    }
   ],
   "source": [
    "query = Qnp\n",
    "dataset = Dnp\n",
    "print(query.shape)\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cf9eda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0e6453",
   "metadata": {},
   "source": [
    "## DTW Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76274b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fastdtwNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -umpy (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\anaconda\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading fastdtw-0.3.4.tar.gz (133 kB)\n",
      "Requirement already satisfied: numpy in d:\\anaconda\\lib\\site-packages (from fastdtw) (1.22.4)\n",
      "Building wheels for collected packages: fastdtw\n",
      "  Building wheel for fastdtw (setup.py): started\n",
      "  Building wheel for fastdtw (setup.py): finished with status 'done'\n",
      "  Created wheel for fastdtw: filename=fastdtw-0.3.4-py3-none-any.whl size=3566 sha256=6d41cd1469ce34ba0e7a1a4856915f590e14b4857c5c5c14d77bb6369741ceb2\n",
      "  Stored in directory: c:\\users\\bilal\\appdata\\local\\pip\\cache\\wheels\\1f\\a1\\63\\bfd0fddb5bf0b59f564872e29272cee8a2de0cd745d88fede5\n",
      "Successfully built fastdtw\n",
      "Installing collected packages: fastdtw\n",
      "Successfully installed fastdtw-0.3.4\n"
     ]
    }
   ],
   "source": [
    "pip install fastdtw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3541434",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 6.95 GiB for an array with shape (2463, 378694) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 34>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m         execution_times[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m end_time \u001b[38;5;241m-\u001b[39m start_time\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dtw_distances, execution_times\n\u001b[1;32m---> 34\u001b[0m dtw_distances, execution_times \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_dtw_for_all_rows\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Print DTW distances and execution times\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDTW Distances:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36mcalculate_dtw_for_all_rows\u001b[1;34m(query_matrix, data_matrix)\u001b[0m\n\u001b[0;32m     16\u001b[0m     num_queries \u001b[38;5;241m=\u001b[39m query_matrix\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     17\u001b[0m     num_data_points \u001b[38;5;241m=\u001b[39m data_matrix\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m---> 19\u001b[0m     dtw_distances \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_queries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_data_points\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m     execution_times \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(num_queries)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m#     for i in range(num_queries):\u001b[39;00m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 6.95 GiB for an array with shape (2463, 378694) and data type float64"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from fastdtw import fastdtw\n",
    "import time\n",
    "\n",
    "def dtw_distance(sequence1, sequence2):\n",
    "    \"\"\"\n",
    "    Calculate the DTW distance between two sequences.\n",
    "    \"\"\"\n",
    "    distance, _ = fastdtw(sequence1, sequence2)\n",
    "    return distance\n",
    "\n",
    "def calculate_dtw_for_all_rows(query_matrix, data_matrix):\n",
    "    \"\"\"\n",
    "    Calculate DTW distance for each row in the query matrix with the corresponding rows in the data matrix.\n",
    "    \"\"\"\n",
    "    num_queries = query_matrix.shape[0]\n",
    "    num_data_points = data_matrix.shape[0]\n",
    "    \n",
    "    dtw_distances = np.zeros((num_queries, num_data_points))\n",
    "    execution_times = np.zeros(num_queries)\n",
    "    \n",
    "#     for i in range(num_queries):\n",
    "    start_time = time.time()\n",
    "        \n",
    "    for j in range(num_data_points):\n",
    "        dtw_distances[0, j] = dtw_distance(query_matrix[0], data_matrix[j])\n",
    "\n",
    "        end_time = time.time()\n",
    "        execution_times[0] = end_time - start_time\n",
    "\n",
    "    return dtw_distances, execution_times\n",
    "\n",
    "\n",
    "dtw_distances, execution_times = calculate_dtw_for_all_rows(query, dataset)\n",
    "\n",
    "# Print DTW distances and execution times\n",
    "print(\"DTW Distances:\")\n",
    "print(dtw_distances)\n",
    "print(\"\\nExecution Times:\")\n",
    "print(execution_times)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8966e1",
   "metadata": {},
   "source": [
    "## Locality-Sensitive Hashing (LSH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae20add",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec0ab78a",
   "metadata": {},
   "source": [
    "# KD TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7151744d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import KDTree\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import time\n",
    "\n",
    "def knn_search_and_evaluate(query, dataset, K):\n",
    "    kdtree = KDTree(dataset)\n",
    "    \n",
    "    # Perform K-nearest neighbor search for the query matrix\n",
    "    start_time = time.time()\n",
    "    distances, indices = kdtree.query(query, k=K)\n",
    "    retrieval_time = time.time() - start_time\n",
    "    print(indices.shape)\n",
    "    \n",
    "    # Initialize variables to store evaluation metrics\n",
    "    mse_list = []\n",
    "    mpjse_list = []\n",
    "    pck_list = []\n",
    "    \n",
    "    # Calculate evaluation metrics for each query pose\n",
    "    for i in range(len(query)):\n",
    "        # Get the K-nearest neighbors from the dataset\n",
    "        nearest_neighbors = dataset[indices[i]]\n",
    "        \n",
    "        # Calculate Mean Squared Error (MSE)\n",
    "#         mse = mean_squared_error(query[i], nearest_neighbors)\n",
    "#         mse_list.append(mse)\n",
    "        \n",
    "        # Calculate Mean Per Joint Squared Error (MPJSE)\n",
    "        mpjse = np.mean(np.linalg.norm(query[i] - nearest_neighbors))\n",
    "        mpjse_list.append(mpjse)\n",
    "        \n",
    "        # Compute PCK (Percentage of Correct Keypoints)\n",
    "        threshold = 30  # Set a threshold for correctness\n",
    "        correct_keypoints = np.linalg.norm(query[i] - nearest_neighbors, axis=1) < threshold\n",
    "        pck = np.sum(correct_keypoints) / len(correct_keypoints)\n",
    "        pck_list.append(pck)\n",
    "        \n",
    "    # Calculate the mean of each evaluation metric\n",
    "#     mean_mse = np.mean(mse_list)\n",
    "    mean_mpjse = np.mean(mpjse_list)\n",
    "    mean_pck = np.mean(pck_list)\n",
    "    \n",
    "#     print(f\"Mean Squared Error (MSE): {mean_mse}\")\n",
    "    print(f\"Mean Per Joint Squared Error (MPJSE): {mean_mpjse}\")\n",
    "    print(f\"Percentage of Correct Keypoints (PCK): {mean_pck}\")\n",
    "    print(f\"Retrieval Time: {retrieval_time} seconds\")\n",
    "    \n",
    "    return mean_mpjse, mean_pck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b28d4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K value is:  2\n",
      "(2463, 2)\n",
      "Mean Per Joint Squared Error (MPJSE): 24.646671295166016\n",
      "Percentage of Correct Keypoints (PCK): 0.9587900933820545\n",
      "Retrieval Time: 27.14136505126953 seconds\n",
      "K value is:  4\n",
      "(2463, 4)\n",
      "Mean Per Joint Squared Error (MPJSE): 36.32893371582031\n",
      "Percentage of Correct Keypoints (PCK): 0.9470158343483557\n",
      "Retrieval Time: 25.554195165634155 seconds\n",
      "K value is:  8\n",
      "(2463, 8)\n",
      "Mean Per Joint Squared Error (MPJSE): 54.428688049316406\n",
      "Percentage of Correct Keypoints (PCK): 0.9251928542427933\n",
      "Retrieval Time: 25.1305148601532 seconds\n",
      "K value is:  16\n",
      "(2463, 16)\n",
      "Mean Per Joint Squared Error (MPJSE): 82.76153564453125\n",
      "Percentage of Correct Keypoints (PCK): 0.8925852618757613\n",
      "Retrieval Time: 29.495342254638672 seconds\n",
      "K value is:  32\n",
      "(2463, 32)\n",
      "Mean Per Joint Squared Error (MPJSE): 127.25959014892578\n",
      "Percentage of Correct Keypoints (PCK): 0.8532785221274868\n",
      "Retrieval Time: 33.92673444747925 seconds\n",
      "K value is:  64\n",
      "(2463, 64)\n",
      "Mean Per Joint Squared Error (MPJSE): 196.8567352294922\n",
      "Percentage of Correct Keypoints (PCK): 0.7952382764920828\n",
      "Retrieval Time: 38.80798363685608 seconds\n",
      "K value is:  128\n",
      "(2463, 128)\n",
      "Mean Per Joint Squared Error (MPJSE): 304.95428466796875\n",
      "Percentage of Correct Keypoints (PCK): 0.7168690367438084\n",
      "Retrieval Time: 50.30242586135864 seconds\n",
      "K value is:  256\n",
      "(2463, 256)\n",
      "Mean Per Joint Squared Error (MPJSE): 472.04193115234375\n",
      "Percentage of Correct Keypoints (PCK): 0.6029232643118149\n",
      "Retrieval Time: 68.60465335845947 seconds\n",
      "K value is:  512\n",
      "(2463, 512)\n",
      "Mean Per Joint Squared Error (MPJSE): 730.660400390625\n",
      "Percentage of Correct Keypoints (PCK): 0.47343734140276084\n",
      "Retrieval Time: 89.58356857299805 seconds\n"
     ]
    }
   ],
   "source": [
    "k = 2\n",
    "while k != 1024:\n",
    "    print(\"K value is: \",k)\n",
    "    knn_search_and_evaluate(query, dataset, k)\n",
    "    k = k*2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289a972c",
   "metadata": {},
   "source": [
    "## KNN With diff metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b7e1c19c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: range\n",
      "Metric: euclidean\n",
      "Mean Per Joint Squared Error (MPJSE): 47.147491455078125\n",
      "Percentage of Correct Keypoints (PCK): 0.031628115229951174\n",
      "Retrieval Time: 127.56776309013367 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors, BallTree\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def knn_search_and_evaluate(query, dataset, K, method='knn', metric='euclidean'):\n",
    "    if method == 'knn':\n",
    "        knn = NearestNeighbors(n_neighbors=K, algorithm='auto', metric=metric)\n",
    "        knn.fit(dataset)\n",
    "        \n",
    "    elif method == 'range':\n",
    "        knn = BallTree(dataset, metric=metric)\n",
    "    \n",
    "    # Fit the model with the dataset\n",
    "    \n",
    "    # Perform K-nearest neighbor search or range search for the query matrix\n",
    "    start_time = time.time()\n",
    "    if method == 'knn':\n",
    "        distances, indices = knn.kneighbors(query)\n",
    "    elif method == 'range':\n",
    "        indices = knn.query_radius(query, r=55.0)\n",
    "    retrieval_time = time.time() - start_time\n",
    "    \n",
    "    # Initialize variables to store evaluation metrics\n",
    "#     mse_list = []\n",
    "    mpjse_list = []\n",
    "    pck_list = []\n",
    "    \n",
    "    # Calculate evaluation metrics for each query pose\n",
    "    for i in range(len(query)):\n",
    "        if method == 'knn':\n",
    "            # Get the K-nearest neighbors from the dataset\n",
    "            nearest_neighbors = dataset[indices[i]]\n",
    "        elif method == 'range':\n",
    "            # Get the neighbors within the specified radius\n",
    "            nearest_neighbors = dataset[indices[i]]\n",
    "        \n",
    "        # Calculate Mean Squared Error (MSE)\n",
    "#         mse = mean_squared_error(query[i], nearest_neighbors)\n",
    "#         mse_list.append(mse)\n",
    "        \n",
    "        # Calculate Mean Per Joint Squared Error (MPJSE)\n",
    "        mpjse = np.mean(np.linalg.norm(query[i] - nearest_neighbors, axis=1))\n",
    "        mpjse_list.append(mpjse)\n",
    "        \n",
    "        # Compute PCK (Percentage of Correct Keypoints)\n",
    "        threshold = 30  # Set a threshold for correctness\n",
    "        correct_keypoints = np.linalg.norm(query[i] - nearest_neighbors, axis=1) < threshold\n",
    "        pck = np.sum(correct_keypoints) / len(correct_keypoints)\n",
    "        pck_list.append(pck)\n",
    "        \n",
    "    # Calculate the mean of each evaluation metric\n",
    "#     mean_mse = np.mean(mse_list)\n",
    "    mean_mpjse = np.mean(mpjse_list)\n",
    "    mean_pck = np.mean(pck_list)\n",
    "    \n",
    "    print(f\"Method: {method}\")\n",
    "    print(f\"Metric: {metric}\")\n",
    "#     print(f\"Mean Squared Error (MSE): {mean_mse}\")\n",
    "    print(f\"Mean Per Joint Squared Error (MPJSE): {mean_mpjse}\")\n",
    "    print(f\"Percentage of Correct Keypoints (PCK): {mean_pck}\")\n",
    "    print(f\"Retrieval Time: {retrieval_time} seconds\")\n",
    "\n",
    "# Example usage:\n",
    "# knn_search_and_evaluate(query, dataset, 32, method='knn', metric='euclidean')\n",
    "knn_search_and_evaluate(query, dataset, 32, method='range', metric='euclidean')\n",
    "# You can call this function with different methods and metrics as needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e2d6888b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: knn\n",
      "Metric: euclidean\n",
      "Mean Per Joint Squared Error (MPJSE): 22.36042594909668\n",
      "Percentage of Correct Keypoints (PCK): 0.8532785221274868\n",
      "Retrieval Time: 28.141523122787476 seconds\n",
      "-------------------------------------------------------------------------\n",
      "\n",
      "Method: knn\n",
      "Metric: cosine\n",
      "Mean Per Joint Squared Error (MPJSE): 22.85877227783203\n",
      "Percentage of Correct Keypoints (PCK): 0.8461987413723102\n",
      "Retrieval Time: 16.68146252632141 seconds\n",
      "-------------------------------------------------------------------------\n",
      "\n",
      "Method: knn\n",
      "Metric: hamming\n",
      "Mean Per Joint Squared Error (MPJSE): 95.14612579345703\n",
      "Percentage of Correct Keypoints (PCK): 0.0010530856678846936\n",
      "Retrieval Time: 136.45128917694092 seconds\n"
     ]
    }
   ],
   "source": [
    "knn_search_and_evaluate(query, dataset, 32, method='knn', metric='euclidean')\n",
    "print(\"-------------------------------------------------------------------------\\n\")\n",
    "knn_search_and_evaluate(query, dataset, 32, method='knn', metric='cosine')\n",
    "# print(\"-------------------------------------------------------------------------\\n\")\n",
    "# knn_search_and_evaluate(query, dataset, 32, method='knn', metric='jaccard')\n",
    "print(\"-------------------------------------------------------------------------\\n\")\n",
    "knn_search_and_evaluate(query, dataset, 32, method='knn', metric='hamming')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c0a3ac4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K value is:  2\n",
      "Method: range\n",
      "Metric: euclidean\n",
      "Mean Per Joint Squared Error (MPJSE): 47.147491455078125\n",
      "Percentage of Correct Keypoints (PCK): 0.031628115229951174\n",
      "Retrieval Time: 115.4296522140503 seconds\n",
      "---------------------------------------------------------------------\n",
      "\n",
      "K value is:  4\n",
      "Method: range\n",
      "Metric: euclidean\n",
      "Mean Per Joint Squared Error (MPJSE): 47.147491455078125\n",
      "Percentage of Correct Keypoints (PCK): 0.031628115229951174\n",
      "Retrieval Time: 150.9068329334259 seconds\n",
      "---------------------------------------------------------------------\n",
      "\n",
      "K value is:  8\n",
      "Method: range\n",
      "Metric: euclidean\n",
      "Mean Per Joint Squared Error (MPJSE): 47.147491455078125\n",
      "Percentage of Correct Keypoints (PCK): 0.031628115229951174\n",
      "Retrieval Time: 127.372403383255 seconds\n",
      "---------------------------------------------------------------------\n",
      "\n",
      "K value is:  16\n",
      "Method: range\n",
      "Metric: euclidean\n",
      "Mean Per Joint Squared Error (MPJSE): 47.147491455078125\n",
      "Percentage of Correct Keypoints (PCK): 0.031628115229951174\n",
      "Retrieval Time: 127.92023730278015 seconds\n",
      "---------------------------------------------------------------------\n",
      "\n",
      "K value is:  32\n",
      "Method: range\n",
      "Metric: euclidean\n",
      "Mean Per Joint Squared Error (MPJSE): 47.147491455078125\n",
      "Percentage of Correct Keypoints (PCK): 0.031628115229951174\n",
      "Retrieval Time: 114.36361789703369 seconds\n",
      "---------------------------------------------------------------------\n",
      "\n",
      "K value is:  64\n",
      "Method: range\n",
      "Metric: euclidean\n",
      "Mean Per Joint Squared Error (MPJSE): 47.147491455078125\n",
      "Percentage of Correct Keypoints (PCK): 0.031628115229951174\n",
      "Retrieval Time: 111.5373363494873 seconds\n",
      "---------------------------------------------------------------------\n",
      "\n",
      "K value is:  128\n",
      "Method: range\n",
      "Metric: euclidean\n",
      "Mean Per Joint Squared Error (MPJSE): 47.147491455078125\n",
      "Percentage of Correct Keypoints (PCK): 0.031628115229951174\n",
      "Retrieval Time: 119.40266585350037 seconds\n",
      "---------------------------------------------------------------------\n",
      "\n",
      "K value is:  256\n",
      "Method: range\n",
      "Metric: euclidean\n",
      "Mean Per Joint Squared Error (MPJSE): 47.147491455078125\n",
      "Percentage of Correct Keypoints (PCK): 0.031628115229951174\n",
      "Retrieval Time: 119.4467146396637 seconds\n",
      "---------------------------------------------------------------------\n",
      "\n",
      "K value is:  512\n",
      "Method: range\n",
      "Metric: euclidean\n",
      "Mean Per Joint Squared Error (MPJSE): 47.147491455078125\n",
      "Percentage of Correct Keypoints (PCK): 0.031628115229951174\n",
      "Retrieval Time: 118.71459126472473 seconds\n",
      "---------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "k = 2\n",
    "while k != 1024:\n",
    "    print(\"K value is: \",k)\n",
    "    knn_search_and_evaluate(query, dataset, k, method='range', metric='euclidean')\n",
    "    k = k*2\n",
    "    print(\"---------------------------------------------------------------------\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94225c71",
   "metadata": {},
   "source": [
    "# ANNOY Algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0d70846",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -umpy (d:\\anaconda\\lib\\site-packages)\n",
      "ERROR: You must give at least one requirement to install (see \"pip help install\")\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\anaconda\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting annoy\n",
      "  Using cached annoy-1.17.3.tar.gz (647 kB)\n",
      "Building wheels for collected packages: annoy\n",
      "  Building wheel for annoy (setup.py): started\n",
      "  Building wheel for annoy (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for annoy\n",
      "Failed to build annoy\n",
      "Installing collected packages: annoy\n",
      "    Running setup.py install for annoy: started\n",
      "    Running setup.py install for annoy: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -umpy (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\anaconda\\lib\\site-packages)\n",
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'D:\\Anaconda\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\Bilal\\\\AppData\\\\Local\\\\Temp\\\\pip-install-2_h7wgxj\\\\annoy_d33b71afb56c4f5d94941c2267c77b59\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\Bilal\\\\AppData\\\\Local\\\\Temp\\\\pip-install-2_h7wgxj\\\\annoy_d33b71afb56c4f5d94941c2267c77b59\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d 'C:\\Users\\Bilal\\AppData\\Local\\Temp\\pip-wheel-l0t4rp9x'\n",
      "       cwd: C:\\Users\\Bilal\\AppData\\Local\\Temp\\pip-install-2_h7wgxj\\annoy_d33b71afb56c4f5d94941c2267c77b59\\\n",
      "  Complete output (29 lines):\n",
      "  D:\\Anaconda\\lib\\site-packages\\setuptools\\__init__.py:80: _DeprecatedInstaller: setuptools.installer and fetch_build_eggs are deprecated.\n",
      "  !!\n",
      "  \n",
      "          ********************************************************************************\n",
      "          Requirements should be satisfied by a PEP 517 installer.\n",
      "          If you are using pip, you can try `pip install --use-pep517`.\n",
      "          ********************************************************************************\n",
      "  \n",
      "  !!\n",
      "    dist.fetch_build_eggs(dist.setup_requires)\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-cpython-39\n",
      "  creating build\\lib.win-amd64-cpython-39\\annoy\n",
      "  copying annoy\\__init__.py -> build\\lib.win-amd64-cpython-39\\annoy\n",
      "  copying annoy\\__init__.pyi -> build\\lib.win-amd64-cpython-39\\annoy\n",
      "  copying annoy\\py.typed -> build\\lib.win-amd64-cpython-39\\annoy\n",
      "  running build_ext\n",
      "  building 'annoy.annoylib' extension\n",
      "  creating build\\temp.win-amd64-cpython-39\n",
      "  creating build\\temp.win-amd64-cpython-39\\Release\n",
      "  creating build\\temp.win-amd64-cpython-39\\Release\\src\n",
      "  D:\\VS\\VC\\Tools\\MSVC\\14.37.32822\\bin\\HostX86\\x64\\cl.exe /c /nologo /O2 /W3 /GL /DNDEBUG /MD -ID:\\Anaconda\\include -ID:\\Anaconda\\Include -ID:\\VS\\VC\\Tools\\MSVC\\14.37.32822\\include -ID:\\VS\\VC\\Tools\\MSVC\\14.37.32822\\ATLMFC\\include -ID:\\VS\\VC\\Auxiliary\\VS\\include /EHsc /Tpsrc/annoymodule.cc /Fobuild\\temp.win-amd64-cpython-39\\Release\\src/annoymodule.obj -D_CRT_SECURE_NO_WARNINGS -fpermissive -DANNOYLIB_MULTITHREADED_BUILD\n",
      "  cl : Command line warning D9002 : ignoring unknown option '-fpermissive'\n",
      "  annoymodule.cc\n",
      "  C:\\Users\\Bilal\\AppData\\Local\\Temp\\pip-install-2_h7wgxj\\annoy_d33b71afb56c4f5d94941c2267c77b59\\src\\annoylib.h(19): fatal error C1083: Cannot open include file: 'stdio.h': No such file or directory\n",
      "  error: command 'D:\\\\VS\\\\VC\\\\Tools\\\\MSVC\\\\14.37.32822\\\\bin\\\\HostX86\\\\x64\\\\cl.exe' failed with exit code 2\n",
      "  ----------------------------------------\n",
      "  ERROR: Failed building wheel for annoy\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\anaconda\\lib\\site-packages)\n",
      "    ERROR: Command errored out with exit status 1:\n",
      "     command: 'D:\\Anaconda\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\Bilal\\\\AppData\\\\Local\\\\Temp\\\\pip-install-2_h7wgxj\\\\annoy_d33b71afb56c4f5d94941c2267c77b59\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\Bilal\\\\AppData\\\\Local\\\\Temp\\\\pip-install-2_h7wgxj\\\\annoy_d33b71afb56c4f5d94941c2267c77b59\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\Bilal\\AppData\\Local\\Temp\\pip-record-okw6ybd3\\install-record.txt' --single-version-externally-managed --compile --install-headers 'D:\\Anaconda\\Include\\annoy'\n",
      "         cwd: C:\\Users\\Bilal\\AppData\\Local\\Temp\\pip-install-2_h7wgxj\\annoy_d33b71afb56c4f5d94941c2267c77b59\\\n",
      "    Complete output (42 lines):\n",
      "    D:\\Anaconda\\lib\\site-packages\\setuptools\\__init__.py:80: _DeprecatedInstaller: setuptools.installer and fetch_build_eggs are deprecated.\n",
      "    !!\n",
      "    \n",
      "            ********************************************************************************\n",
      "            Requirements should be satisfied by a PEP 517 installer.\n",
      "            If you are using pip, you can try `pip install --use-pep517`.\n",
      "            ********************************************************************************\n",
      "    \n",
      "    !!\n",
      "      dist.fetch_build_eggs(dist.setup_requires)\n",
      "    running install\n",
      "    D:\\Anaconda\\lib\\site-packages\\setuptools\\_distutils\\cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
      "    !!\n",
      "    \n",
      "            ********************************************************************************\n",
      "            Please avoid running ``setup.py`` directly.\n",
      "            Instead, use pypa/build, pypa/installer or other\n",
      "            standards-based tools.\n",
      "    \n",
      "            See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
      "            ********************************************************************************\n",
      "    \n",
      "    !!\n",
      "      self.initialize_options()\n",
      "    running build\n",
      "    running build_py\n",
      "    creating build\n",
      "    creating build\\lib.win-amd64-cpython-39\n",
      "    creating build\\lib.win-amd64-cpython-39\\annoy\n",
      "    copying annoy\\__init__.py -> build\\lib.win-amd64-cpython-39\\annoy\n",
      "    copying annoy\\__init__.pyi -> build\\lib.win-amd64-cpython-39\\annoy\n",
      "    copying annoy\\py.typed -> build\\lib.win-amd64-cpython-39\\annoy\n",
      "    running build_ext\n",
      "    building 'annoy.annoylib' extension\n",
      "    creating build\\temp.win-amd64-cpython-39\n",
      "    creating build\\temp.win-amd64-cpython-39\\Release\n",
      "    creating build\\temp.win-amd64-cpython-39\\Release\\src\n",
      "    D:\\VS\\VC\\Tools\\MSVC\\14.37.32822\\bin\\HostX86\\x64\\cl.exe /c /nologo /O2 /W3 /GL /DNDEBUG /MD -ID:\\Anaconda\\include -ID:\\Anaconda\\Include -ID:\\VS\\VC\\Tools\\MSVC\\14.37.32822\\include -ID:\\VS\\VC\\Tools\\MSVC\\14.37.32822\\ATLMFC\\include -ID:\\VS\\VC\\Auxiliary\\VS\\include /EHsc /Tpsrc/annoymodule.cc /Fobuild\\temp.win-amd64-cpython-39\\Release\\src/annoymodule.obj -D_CRT_SECURE_NO_WARNINGS -fpermissive -DANNOYLIB_MULTITHREADED_BUILD\n",
      "    cl : Command line warning D9002 : ignoring unknown option '-fpermissive'\n",
      "    annoymodule.cc\n",
      "    C:\\Users\\Bilal\\AppData\\Local\\Temp\\pip-install-2_h7wgxj\\annoy_d33b71afb56c4f5d94941c2267c77b59\\src\\annoylib.h(19): fatal error C1083: Cannot open include file: 'stdio.h': No such file or directory\n",
      "    error: command 'D:\\\\VS\\\\VC\\\\Tools\\\\MSVC\\\\14.37.32822\\\\bin\\\\HostX86\\\\x64\\\\cl.exe' failed with exit code 2\n",
      "    ----------------------------------------\n",
      "ERROR: Command errored out with exit status 1: 'D:\\Anaconda\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\Bilal\\\\AppData\\\\Local\\\\Temp\\\\pip-install-2_h7wgxj\\\\annoy_d33b71afb56c4f5d94941c2267c77b59\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\Bilal\\\\AppData\\\\Local\\\\Temp\\\\pip-install-2_h7wgxj\\\\annoy_d33b71afb56c4f5d94941c2267c77b59\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\Bilal\\AppData\\Local\\Temp\\pip-record-okw6ybd3\\install-record.txt' --single-version-externally-managed --compile --install-headers 'D:\\Anaconda\\Include\\annoy' Check the logs for full command output.\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\anaconda\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install --use-pep517\n",
    "!pip install annoy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ca3647d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'annoy.annoylib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mannoy\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mannoy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AnnoyIndex\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mannoy_search_and_evaluate\u001b[39m(query, dataset, K, metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meuclidean\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# Build AnnoyIndex for both KNN and range search\u001b[39;00m\n",
      "File \u001b[1;32mD:\\University\\FYP\\Implementation\\HDM_01-01_amc\\annoy\\__init__.py:16\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright (c) 2013 Spotify AB\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\"); you may not\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m \n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# This module is a dummy wrapper around the underlying C++ module.\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mannoylib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Annoy \u001b[38;5;28;01mas\u001b[39;00m AnnoyIndex\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'annoy.annoylib'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import annoy\n",
    "from annoy import AnnoyIndex\n",
    "\n",
    "def annoy_search_and_evaluate(query, dataset, K, metric='euclidean'):\n",
    "    # Build AnnoyIndex for both KNN and range search\n",
    "    num_trees = 10  # You can adjust the number of trees for performance vs. accuracy trade-off\n",
    "    annoy_index = AnnoyIndex(dataset.shape[1], metric=metric)\n",
    "    for i, vec in enumerate(dataset):\n",
    "        annoy_index.add_item(i, vec)\n",
    "    annoy_index.build(num_trees)\n",
    "    \n",
    "    # Perform K-nearest neighbor search for the query matrix\n",
    "    start_time = time.time()\n",
    "    indices_knn = [annoy_index.get_nns_by_vector(vec, K, search_k=-1, include_distances=False) for vec in query]\n",
    "    knn_retrieval_time = time.time() - start_time\n",
    "    \n",
    "    # Perform range search for the query matrix\n",
    "    start_time = time.time()\n",
    "    indices_range = [annoy_index.get_nns_by_vector(vec, K, search_k=-1, include_distances=False) for vec in query]\n",
    "    range_retrieval_time = time.time() - start_time\n",
    "    \n",
    "    # Initialize variables to store evaluation metrics\n",
    "    mpjse_list_knn = []\n",
    "    mpjse_list_range = []\n",
    "    pck_list_knn = []\n",
    "    pck_list_range = []\n",
    "    \n",
    "    # Calculate evaluation metrics for each query pose for KNN search\n",
    "    for i in range(len(query)):\n",
    "        nearest_neighbors_knn = dataset[indices_knn[i]]\n",
    "        \n",
    "        # Calculate Mean Per Joint Squared Error (MPJSE)\n",
    "        mpjse_knn = np.mean(np.linalg.norm(query[i] - nearest_neighbors_knn, axis=1))\n",
    "        mpjse_list_knn.append(mpjse_knn)\n",
    "        \n",
    "        # Compute PCK (Percentage of Correct Keypoints)\n",
    "        threshold = 30  # Set a threshold for correctness\n",
    "        correct_keypoints_knn = np.linalg.norm(query[i] - nearest_neighbors_knn, axis=1) < threshold\n",
    "        pck_knn = np.sum(correct_keypoints_knn) / len(correct_keypoints_knn)\n",
    "        pck_list_knn.append(pck_knn)\n",
    "    \n",
    "    # Calculate evaluation metrics for each query pose for range search\n",
    "    for i in range(len(query)):\n",
    "        nearest_neighbors_range = dataset[indices_range[i]]\n",
    "        \n",
    "        # Calculate Mean Per Joint Squared Error (MPJSE)\n",
    "        mpjse_range = np.mean(np.linalg.norm(query[i] - nearest_neighbors_range, axis=1))\n",
    "        mpjse_list_range.append(mpjse_range)\n",
    "        \n",
    "        # Compute PCK (Percentage of Correct Keypoints)\n",
    "        correct_keypoints_range = np.linalg.norm(query[i] - nearest_neighbors_range, axis=1) < threshold\n",
    "        pck_range = np.sum(correct_keypoints_range) / len(correct_keypoints_range)\n",
    "        pck_list_range.append(pck_range)\n",
    "    \n",
    "    # Calculate the mean of each evaluation metric for KNN search\n",
    "    mean_mpjse_knn = np.mean(mpjse_list_knn)\n",
    "    mean_pck_knn = np.mean(pck_list_knn)\n",
    "    \n",
    "    # Calculate the mean of each evaluation metric for range search\n",
    "    mean_mpjse_range = np.mean(mpjse_list_range)\n",
    "    mean_pck_range = np.mean(pck_list_range)\n",
    "    \n",
    "    print(\"KNN Search:\")\n",
    "    print(f\"Metric: {metric}\")\n",
    "    print(f\"Mean Per Joint Squared Error (MPJSE): {mean_mpjse_knn}\")\n",
    "    print(f\"Percentage of Correct Keypoints (PCK): {mean_pck_knn}\")\n",
    "    print(f\"Retrieval Time: {knn_retrieval_time} seconds\\n\")\n",
    "    \n",
    "    print(\"Range Search:\")\n",
    "    print(f\"Metric: {metric}\")\n",
    "    print(f\"Mean Per Joint Squared Error (MPJSE): {mean_mpjse_range}\")\n",
    "    print(f\"Percentage of Correct Keypoints (PCK): {mean_pck_range}\")\n",
    "    print(f\"Retrieval Time: {range_retrieval_time} seconds\")\n",
    "\n",
    "# Example usage:\n",
    "annoy_search_and_evaluate(query, dataset, 32, metric='euclidean')\n",
    "# You can call this function with different metrics as needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7799161",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
